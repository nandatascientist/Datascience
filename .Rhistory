demo90
demo()
quit90
qui()
quit()
demo()
find.package("devtools")
find.package("XML")
install.packages("KernSmooth")
library(KernSmooth)
find.package("devtools")
install.packages("devtools")
library(devtools)
install.packages("memoise")
install.packages("whisker")
install.packages("evaluate")
install.packages("evaluate")
library(devtools)
find_rtools()
help("gl")
library(datasets)
data(iris)
?iris
class(iris)
names(iris)
iris$names
colnames(iris)
?split
l<-split(iris,colnames(iris))
sapply(l,mean)
head(iris)
rm(l)
l<-split(iris,iris$Species)
?colmeans
?colMeans
help("colmeans")
help("colMeans")
colMeans(l[1])
l[1]
library(sqldf)
install.packages("sqldf")
library(sqldf)
getwd()
setwd("C:/Users/koushikk/repos/Datascience")
?download.file
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv","acs.csv",method="curl",extra="-o")
url<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(url,"./acs.csv",method="curl",extra="-o")
fileUrl<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl,destfile="./acs.csv",method="curl" extra="-k")
download.file(fileUrl,destfile="./acs.csv",method="curl", extra="-k")
getwd()
acs<-read.csv("acs.csv")
class(acs)
nrow(acs)
ncol(acs)
sqldf("select pwgtp1 from acs where AGEP < 50")
unique(acs$AGEP)
sqldf("select distinct AGEP from acs")
?rm
rm(acs)
doc<-htmltreeparse("http://biostat.jhsph.edu/~jleek/contact.html",useInternal=TRUE)
library(XML)
doc<-htmlTreeParse("http://biostat.jhsph.edu/~jleek/contact.html",useInternal=TRUE)
class(doc)
test<-content(doc)
?content
library(JSONlite)
library(jsonlite)
?content
test<-as.character(doc)
?unlist
?readlines
?readLines
content<readLines("http://biostat.jhsph.edu/~jleek/contact.html")
content<-readLines("http://biostat.jhsph.edu/~jleek/contact.html")
class(content)
length(content)
content[1]
content[10]
?nchar
nchar(content[10])
nchar(content[20])
nchar(content[30])
nchar(content[100])
url<-"https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
download.file(url,destfile="./tabdelim.tab",method="curl", extra="-k")
?read.date
?read.data
?read.table
df<-read.table("tab.delim",sep="",header=TRUE)
df<-read.table("tabdelim.tab",sep="",header=TRUE)
df<-read.table("tabdelim.tab",sep="",header=TRUE, skip=3)
df<-read.table("tabdelim.tab",sep="", skip=3)
df<-read.table("tabdelim.tab",skip=3)
df<-read.table("tabdelim.tab",skip=3,fill=TRUE)
nrow(df)
ncol(df)
names(df)
class(v4)
class(df$v4)
head(df,10)
df<-read.table("tabdelim.tab",skip=3,fill=TRUE,header=TRUE)
head(df,10)
df<-read.table("tabdelim.tab",skip=3,fill=TRUE,header=TRUE,comment.char="-")
head(df,10)
df<-read.table("tabdelim.tab",skip=3,fill=TRUE)
head(df,10)
sum(df[,4])
class(df[,4])
df[,4]<-as.numeric(df[,4])
sum(df[,4])
head(df)
df<-read.table("tabdelim.tab",skip=3,fill=TRUE,quote="-")
head(df)
?str_replace_all
library(stringr)
?str_replace_all
text <- readLines("tabdelim.tab",encoding="UTF-8")
head(text)
newtext<-str_replace_all(text,"-"." ")
newtext<-str_replace_all(text,"-"," ")
head(text)
head(newtext)
df<-read.table(newtext,skip=3,quotes="",fill=TRUE)
?read.table
df<-read.table(newtext,skip=3,quote="",fill=TRUE)
?writeLined()
?writeLines()
head(newtext)
filecon<-file("cleanfile.tab")
writeLines(newtext,filecon,sep="\n")
close(filecon)
getwd()
df<-read.table("cleanfile.tab",skip=3,quotes="",fill=TRUE)
df<-read.table("cleanfile.tab",skip=3,quote="",fill=TRUE)
head(df)
df<-read.table("cleanfile.tab",skip=3,quote="",fill=TRUE,header=TRUE)
head(df)
df[,4]<-as.numeric(df[,4])
sum(df[,4])
