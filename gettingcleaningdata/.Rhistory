demo90
demo()
quit90
qui()
quit()
demo()
find.package("devtools")
find.package("XML")
install.packages("KernSmooth")
library(KernSmooth)
find.package("devtools")
install.packages("devtools")
library(devtools)
install.packages("memoise")
install.packages("whisker")
install.packages("evaluate")
install.packages("evaluate")
library(devtools)
find_rtools()
help("gl")
library(datasets)
data(iris)
?iris
class(iris)
names(iris)
iris$names
colnames(iris)
?split
l<-split(iris,colnames(iris))
sapply(l,mean)
head(iris)
rm(l)
l<-split(iris,iris$Species)
?colmeans
?colMeans
help("colmeans")
help("colMeans")
colMeans(l[1])
l[1]
library(plyr)
data(airQuality)
data(airquality)
names(airquality)
View(airquality)
arrange(airquality,ozone)
arrange(airquality,airquality$Ozone)
airquality[airquality$Month==5 & airquality$day>20,]
arrange(airquality,airquality$Month)
airquality[airquality$Month==5 & airquality$Day>20,]
getwd()
setwd("C:/Users/koushikk/repos/Datascience/gettingcleaningdata")
data(airquality)
names(airquality)
testdf<-airquality
tolower(names(testdf))
namelist<-splitnames(names(testdf),"//.")
namelist<-strsplit(names(testdf),"//.")
namelist
namelist<-strsplit(names(testdf),"\\.")
namelist
namelist[2]
namelist[2][1]
namelist[[2]]
namelist[[2]][1]
firstelement<- function(x){ x[1]}
sapply(namelist,firstelement)
testdf<-airquality
names(testdf)
gsub(".","",names(testdf))
names(testdf)
?sub
?sub
gsub(".","",names(testdf),)
names(testdf)
gsub("//.","",names(testdf),)
gsub("//.","",names(testdf))
gsub("\\.","",names(testdf))
names(airquality)
tolower(names(testdf))
unique(testdf$ozone)
class(testdf$ozone)
testdf
names(testdf)<-tolower(names(testdf))
unique(testdf$ozone)
grepl("^4",testdf$ozone)
grepl("^4",unique(testdf$ozone))
?str_trim
library(stringr)
?str_trim
d1<=date()
d1<-date()
d1
d2<-Sys.Date()
d2
getwd
getwd()
download.file(url,destfile="./housing.csv",method="curl", extra="-k")
download.file(url,destfile="./housing.csv",method="curl", extra="-k")
url<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(url,destfile="./housing.csv",method="curl", extra="-k")
download.file(url,destfile="./housing.csv",method="curl", extra="-k")
housingdf<-read.csv("housing.csv")
names(housingdf)
splitlist<-strsplit(names(housingdf),"wgtp")
splitlist[123]
url<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(url,destfile="./GDP.csv",method="curl", extra="-k")
rawdf<-read.csv("GDP.csv",skip=3, header=TRUE)
View(rawdf)
?read.csv
rawdf<-read.csv("GDP.csv",skip=3, header=TRUE, blank.lines.skip=TRUE)
View(rawdf)
good<-which(rawdf$Ranking>0)
head(rawdf)
good<-which(!is.na(as.numeric(rawdf$Ranking)))
rawdf[good,]
good
good<-which(!is.na(as.numeric(rawdf$Ranking)) & as.numeric(rawdf$Ranking)>0)
good
as.numeric(rawdf$Ranking)
toberemoved<-which(is.na(rawdf$Ranking)| rawdf$Ranking=="" |rawdf$CountryCode=="" )
gdpdf<-rawdf[-toberemoved,c(1,2,4,5)]
url<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(url,destfile="./GDP.csv",method="curl", extra="-k")
download.file(url,destfile="./GDP.csv",method="curl", extra="-k")
rawdf<-read.csv("GDP.csv",skip=3, header=TRUE, blank.lines.skip=TRUE)
toberemoved<-which(is.na(rawdf$Ranking)| rawdf$Ranking=="" |rawdf$CountryCode=="" )
names(rawdf)[names(rawdf)=="X"]<-"CountryCode"
toberemoved<-which(is.na(rawdf$Ranking)| rawdf$Ranking=="" |rawdf$CountryCode=="" )
gdpdf<-rawdf[-toberemoved,c(1,2,4,5)]
View(gdpdf)
View(gdpdf)
names(gdpdf)<-gsub("\\.","",names(gdpdf))
View(gdpdf)
names(gdpdf)<-tolower(gsub("\\.","",names(gdpdf)))
names(gdpdf)
gdpdf$usd<-gsub(",","",gdpdf$usdollars)
head(gdpdf$usd)
gdpdf$usd<-as.numeric(gdpdf$usd)
View(gdpdf)
head(gdpdf[,c(5,6)])
head(gdpdf[,c(4,5)])
class(gdpdf$usd)
mean(gdp$usd)
mean(gdpdf$usd)
names(gdpdf)
head(gdpdf)
grep("^United",countryNames), 3
grep("^United",countryNames), 3)
?grep
grep("^[Uu]nited",gdpdf$economy)
grep("^[Uu]nited",gdpdf$economy,value=TRUE)
download.file(url,destfile="./edstats1.csv",method="curl", method="-k")
url<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(url,destfile="./edstats1.csv",method="curl", method="-k")
url1<-"https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(url1,destfile="./edstats1.csv",method="curl", method="-k")
download.file(url1,destfile="./edstats1.csv",method="curl", extra="-k")
edstatsdf<-read.csv("edstats1.csv",strip.white=TRUE)
names(edstatsdf)
mergedf<-merge(gdpdf,edstatsdf,by.x="CountryCode",by.y="CountryCode", all=TRUE)
names(gdfdf)
names(gdpdf)
names(edstatsdf)<-tolower(names(edstatsdf))
names(edstats)
names(edstatsdf)
mergedf<-merge(gdpdf,edstatsdf,by.x="countrycode",by.y="countrycode", all=TRUE)
names(mergedf)
head(mergedf,n=1)
names(mergedf)
names(edstatsdf)<-gsub("\\.","",names(edstatsdf))
names(edstatsdf)
grep("[Ff]iscal [Yy]ear [Ee]nd: [Jj]un*",mergedf$specialnotes,value=TRUE)
grep("[Ff]iscal [Yy]ear [Ee]nd",mergedf$specialnotes,value=TRUE)
grep("[Ff]iscal [Yy]ear [Ee]nd",mergedf$specialnotes)
View(mergedf)
grep("Fiscal year end",mergedf$specialnotes)
grep(" +Fiscal+ year+ end",mergedf$specialnotes)
grep("Fiscal",mergedf$specialnotes)
mergedf$specialnotes
View(mergedf)
mergedf<-merge(gdpdf,edstatsdf,by.x="countrycode",by.y="countrycode", all=TRUE)
mergedf$specialnotes
grep("Fiscal",mergedf$specialnotes)
grep(" +Fiscal+ year+ end",mergedf$specialnotes)
grep("^(.*)Fiscal+ year+ end",mergedf$specialnotes)
grep("^(.*)[Ff]iscal+ [Yy]ear+ [Ee]nd",mergedf$specialnotes)
grep("^(.*)[Ff]iscal+ [Yy]ear+ [Ee]nd:",mergedf$specialnotes)
grep("^(.*)[Ff]iscal+ [Yy]ear+ [Ee]nd(.*)[Jj]un",mergedf$specialnotes)
grep("^(.*)[Ff]iscal+ [Yy]ear+ [Ee]nd(.*)[Jj]un",mergedf$specialnotes,value=true)
grep("^(.*)[Ff]iscal+ [Yy]ear+ [Ee]nd(.*)[Jj]un",mergedf$specialnotes,value=TRUE)
length(grep("^(.*)[Ff]iscal+ [Yy]ear+ [Ee]nd:",mergedf$specialnotes))
length(grep("^(.*)[Ff]iscal+ [Yy]ear+ [Ee]nd(.*)[Jj]un",mergedf$specialnotes))
grep("^(.*)[Ff]iscal+ [Yy]ear+ [Ee]nd:",mergedf$specialnotes)
grep("^(.*)[Ff]iscal+ [Yy]ear+ [Ee]nd:",mergedf$specialnotes,values=TRUE)
grep("^(.*)[Ff]iscal+ [Yy]ear+ [Ee]nd:",mergedf$specialnotes,value=TRUE)
library(quantmod)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
amzn <- getSymbols("AMZN",auto.assign=FALSE)
View(amzn)
sampleTimes<-index(amzn)
class(sampleTimes)
sampleTimes
library(lubridate)
install.packages("lubridate")
in2012<-which(y(sampletimes)=="2012")
?year
?years
in2012<-which(format(sampletimes,"%Y")=="2012")
in2012<-which(format(sampleTimes,"%Y")=="2012")
in2012
length(in2012)
in2012<-which(format(sampleTimes,"%Y")=="2012")
length(in2012)
format(sampleTimes[1],"%Y%a")
in2012mon<-which(format(sampleTimes,"%Y%a")=="2012Mon")
length(in2012mon)
getwd()
setwd("~/Koushik/Professional/Education/Data Science Track/3. Getting and Cleaning Data/Peer Evaluations")
dir()
test1<-read.table("s1.txt")
names(test1)
length(which(test1$subjectID))
?which
table(test1$subjectID)
nrows(test1)
nrow(test1)
2370/30
test2<-read.table("s2.txt")
names(test2)
head(test2)
dim(test2)
test3<-read.table("s3.txt")
names(test3)
head(test3)
dim(test3)
test5<-read.table("s5.txt")
test5<-read.table("s5.txt")
data(Iris)
data(iris)
names(iris)
dim(iris)
table(iris$Species)
test<-read.table("dataset_317_1.txt")
names(test)
head(test)
table(test$v5)
test$v5
table(test$V5)
?solve
getwd()
getwd()
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
fileName <- "./data/smartphone.zip"
if (!file.exists(fileName)) {
download.file(fileUrl, destfile = fileName, method="curl")
list.files("./data")
}
if (!file.exists(fileName)) {
download.file(fileUrl, destfile = fileName, method="curl" method="-k")
list.files("./data")
}
if (!file.exists(fileName)) {
download.file(fileUrl, destfile = fileName, method="curl" method="-k")
list.files("./data")
}
if (!file.exists(fileName)) {
download.file(fileUrl, destfile = fileName, method="curl" method="-k")
list.files("./data")
if (!file.exists(fileName)) {
download.file(fileUrl, destfile = fileName, method="curl", method="-k")
list.files("./data")
}
if (!file.exists(fileName)) {
download.file(fileUrl, destfile = fileName, method="curl", method= "-k")
list.files("./data")
}
?data.table
library(data.table)
?data.table
setwd("C:/Users/koushikk/repos/Datascience/gettingcleaningdata")
?do.call
